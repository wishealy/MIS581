import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from caas_jupyter_tools import display_dataframe_to_user

# Reload source tables
src_path = "/mnt/data/SetUpDataframeTables.xlsx"
xlsx = pd.ExcelFile(src_path)
tables = {name: pd.read_excel(src_path, sheet_name=name) for name in xlsx.sheet_names}
keep_names = [n for n in tables if not n.startswith("zz")]
tbl = {n: tables[n].copy() for n in keep_names}

params = tbl["Monitoring Parameters"].copy()
param_values = tbl["Parameter Values"].copy()
ind_info = tbl["Industrial Facility Information"].copy()
wq = tbl["WWTP Information"].copy()

# Normalize columns to strings for inspection
ind_info.columns = [str(c) for c in ind_info.columns]

# Parameter IDs
param_ids = params["Parameter ID"].dropna().astype(str).unique().tolist()

# Try to find a good facility name/id column
cand_name_cols = [c for c in ind_info.columns if ("name" in c.lower()) or ("facility" in c.lower())]
cand_id_cols = [c for c in ind_info.columns if ("id" in c.lower()) and ("wwtp" not in c.lower())]

fac_name_col = cand_name_cols[0] if cand_name_cols else ind_info.columns[0]
fac_id_col = cand_id_cols[0] if cand_id_cols else None

facilities = ind_info[[fac_name_col] + ([fac_id_col] if fac_id_col else [])].dropna(subset=[fac_name_col]).drop_duplicates()
facility_names = facilities[fac_name_col].astype(str).str.strip().unique().tolist()

# WWTP ID
wwtp_id = int(wq["WWTP ID"].iloc[0]) if "WWTP ID" in wq.columns else 1

# --- Parameter Values synthetic ---
pv = param_values.copy()
pv_out = pd.DataFrame({"Parameter ID": param_ids})
num_cols = [c for c in pv.columns if c != "Parameter ID"]

rng = np.random.default_rng(42)

def baseline_for_param(pid: str):
    key = pid.lower()
    if any(k in key for k in ["arsenic", "cadmium", "mercury", "lead", "nickel", "chromium", "silver", "selenium", "molybdenum", "antimony", "beryllium", "thallium"]):
        return 0.05, 0.2
    if any(k in key for k in ["bod", "tss", "cod"]):
        return 200, 0.6
    if any(k in key for k in ["ammonia", "nh3", "tkn"]):
        return 25, 0.5
    if "chloride" in key:
        return 250, 0.4
    if "sulfate" in key:
        return 300, 0.4
    if "cyanide" in key or "phenol" in key:
        return 0.2, 0.5
    if "phosphorus" in key or "tp." in key:
        return 5, 0.5
    if "tn." in key or "nitrogen" in key:
        return 25, 0.5
    if "ph" in key:
        return 7, 0.2
    return 10, 0.6

for col in num_cols:
    col_l = str(col).lower()
    if any(k in col_l for k in ["limit", "standard", "criteria"]):
        vals = []
        for pid in pv_out["Parameter ID"]:
            mean, sigma = baseline_for_param(pid)
            lim = rng.uniform(0.5*mean, 1.5*mean)
            vals.append(lim)
        pv_out[col] = np.array(vals)
    elif any(k in col_l for k in ["removal", "efficiency"]):
        pv_out[col] = rng.uniform(55, 98.5, size=len(pv_out))
    elif any(k in col_l for k in ["flow", "load", "lb/d"]):
        vals = []
        for pid in pv_out["Parameter ID"]:
            mean, sigma = baseline_for_param(pid)
            mgL = rng.uniform(0.3*mean, 1.8*mean)
            load = 8.34 * mgL * rng.uniform(3, 15)
            vals.append(load)
        pv_out[col] = np.array(vals)
    else:
        pv_out[col] = rng.lognormal(mean=np.log(5), sigma=0.8, size=len(pv_out))

# 5% missingness
for col in pv_out.columns:
    if col == "Parameter ID":
        continue
    mask = rng.random(len(pv_out)) < 0.05
    pv_out.loc[mask, col] = np.nan

# Monitoring Data: all params monitored at WWTP
md_out = pd.DataFrame({"WWTP ID": [wwtp_id]*len(param_ids), "Parameter ID": param_ids})

# Industrial Allocation Limits
limit_cols = [c for c in pv_out.columns if "limit" in str(c).lower()]
limit_lookup = {}
if limit_cols:
    limit_col = limit_cols[0]
    limit_lookup = dict(zip(pv_out["Parameter ID"], pv_out[limit_col]))

rows = []
for fac in facility_names:
    chosen_params = rng.choice(param_ids, size=min(max(10, len(param_ids)//3), len(param_ids)), replace=False)
    for pid in chosen_params:
        base_mean, _ = baseline_for_param(pid)
        lim = float(limit_lookup.get(pid, rng.uniform(0.6*base_mean, 1.4*base_mean)))
        load_lim = float(8.34 * lim * rng.uniform(0.05, 0.6))
        rows.append({
            "WWTP ID": wwtp_id,
            "Industrial Facility Name": fac,
            "Parameter ID": pid,
            "Permit Limit (Conc. mg/L)": lim,
            "Permit Limit (Load lb/d)": load_lim
        })
ial_out = pd.DataFrame(rows)
for col in ["Permit Limit (Conc. mg/L)", "Permit Limit (Load lb/d)"]:
    mask = rng.random(len(ial_out)) < 0.03
    ial_out.loc[mask, col] = np.nan

# Industrial User Concentration (~9000 rows)
target_rows = 9000
pairs = []
for fac in facility_names:
    if len(param_ids) >= 6:
        chosen = rng.choice(param_ids, size=6, replace=False)
    else:
        chosen = param_ids
    for pid in chosen:
        pairs.append((fac, pid))
rng.shuffle(pairs)

samples = []
start_date = datetime(2024, 1, 1)
for fac, pid in pairs:
    n = int(rng.integers(8, 30))
    plim_series = ial_out.loc[(ial_out["Industrial Facility Name"] == fac) & (ial_out["Parameter ID"] == pid), "Permit Limit (Conc. mg/L)"]
    plim = plim_series.iloc[0] if not plim_series.empty else np.nan
    mean_c, sigma_c = baseline_for_param(pid)
    if pd.notna(plim):
        base = max(0.7 * plim, 1e-3)
        data = rng.lognormal(mean=np.log(base), sigma=0.4, size=n)
        spike_mask = rng.random(n) < 0.10
        data[spike_mask] *= rng.uniform(1.2, 3.0, size=spike_mask.sum())
    else:
        data = rng.lognormal(mean=np.log(max(mean_c, 1e-3)), sigma=0.6, size=n)
    dates = [start_date + timedelta(days=int(i)) for i in np.cumsum(rng.integers(1, 20, size=n))]
    for val, dt in zip(data, dates):
        samples.append({
            "WWTP ID": wwtp_id,
            "Industrial Facility Name": fac,
            "Parameter ID": pid,
            "Recorded Value": float(val),
            "Date Collected": dt.date()
        })
    if len(samples) >= target_rows:
        break

iuc_out = pd.DataFrame(samples).head(target_rows)

# Inject messy bits
mask_nan = rng.random(len(iuc_out)) < 0.07
iuc_out.loc[mask_nan, "Recorded Value"] = np.nan
mask_str = rng.random(len(iuc_out)) < 0.02
iuc_out.loc[mask_str, "Recorded Value"] = iuc_out.loc[mask_str, "Recorded Value"].round(2).astype(str)
idx_outliers = iuc_out.sample(frac=0.005, random_state=42).index
iuc_out.loc[idx_outliers, "Recorded Value"] = pd.to_numeric(iuc_out.loc[idx_outliers, "Recorded Value"], errors="coerce") * rng.uniform(5, 15, size=len(idx_outliers))

# Summaries
summary = {
    "Parameter Values rows": len(pv_out),
    "Monitoring Data rows": len(md_out),
    "Ind. Allocation Limits rows": len(ial_out),
    "Ind User Concentration rows": len(iuc_out),
    "TOTAL rows across 4 tables": len(pv_out) + len(md_out) + len(ial_out) + len(iuc_out)
}

# Save to new Excel
out_path = "/mnt/data/synthetic_industrial_dataset.xlsx"
with pd.ExcelWriter(out_path, engine="xlsxwriter") as writer:
    pv_out.to_excel(writer, index=False, sheet_name="Parameter Values")
    md_out.to_excel(writer, index=False, sheet_name="Monitoring Data")
    ial_out.to_excel(writer, index=False, sheet_name="Ind. Allocation Limits")
    iuc_out.to_excel(writer, index=False, sheet_name="Ind User Concentration")

# Show previews
display_dataframe_to_user("Parameter Values (preview)", pv_out.head(15))
display_dataframe_to_user("Monitoring Data (preview)", md_out.head(20))
display_dataframe_to_user("Ind. Allocation Limits (preview)", ial_out.head(20))
display_dataframe_to_user("Ind User Concentration (preview)", iuc_out.head(20))

summary
